batch_size: 64
model:
    dim_feedforward: 2048
    dropout: 0.2
    embedding_dim: 512
    hidden_dim: 512
    image_size: !!python/tuple
    - 128
    - 512
    max_length: 1024
    num_channels: 3
    num_decoder_layers: 4
    num_encoder_layers: 4
    num_heads: 8
    patch_size: 16
    qkv_bias: true
    vocab_size: 94
num_epochs: 100
num_workers: 16
optimizer:
    betas: !!python/tuple
    - 0.9
    - 0.98
    eps: 1.0e-09
    learning_rate: 0.0005
    warmup_steps: 8000
    weight_decay: 0.01